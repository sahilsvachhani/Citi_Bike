{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0275bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Allow notebook to find `src/` folder for imports\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b188bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction FG version: 2\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import src.config as c\n",
    "print(\"Prediction FG version:\", c.FEATURE_GROUP_MODEL_PREDICTION_VERSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8879c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import logging, sys\n",
    "import hopsworks\n",
    "\n",
    "from src.data_utils import (\n",
    "    load_and_process_citibike_data_from_local,\n",
    "    transform_raw_data_into_ts_data,\n",
    ")\n",
    "import src.config as config\n",
    "from hsfs.feature import Feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3c220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import load_and_process_citibike_data_from_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671a76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at the top of your notebook\n",
    "from src.data_utils import load_and_process_citibike_data_from_local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "012957a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:24:46,263 INFO: 📅 Loading Citi Bike data from Jan 2023 to Mar 2025 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:27:12,480 INFO: ✅ Total rows loaded: 799,733\n",
      "['5329.03' '6140.05' '6948.10']\n",
      "            ride_id  rideable_type         pickup_datetime  \\\n",
      "0  A46D077151843D7B   classic_bike 2023-01-16 10:39:54.386   \n",
      "1  233875BAED2E02D0   classic_bike 2023-01-12 16:55:30.755   \n",
      "2  8DD222EA1A1B0BC9  electric_bike 2023-01-08 19:32:25.647   \n",
      "3  58976A4F584F8D28   classic_bike 2023-01-27 20:01:52.897   \n",
      "4  FDD4C1E89A26727C   classic_bike 2023-01-13 18:02:38.160   \n",
      "\n",
      "                  ended_at     start_station_name pickup_location_id  \\\n",
      "0  2023-01-16 10:45:18.005  West St & Chambers St            5329.03   \n",
      "1  2023-01-12 17:04:03.688  West St & Chambers St            5329.03   \n",
      "2  2023-01-08 19:42:00.382  West St & Chambers St            5329.03   \n",
      "3  2023-01-27 20:08:58.118  West St & Chambers St            5329.03   \n",
      "4  2023-01-13 18:11:22.139  West St & Chambers St            5329.03   \n",
      "\n",
      "  end_station_name end_station_id  start_lat  start_lng    end_lat    end_lng  \\\n",
      "0   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
      "1   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
      "2   West Thames St        5114.06  40.717618 -74.013071  40.708347 -74.017134   \n",
      "3   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
      "4   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
      "\n",
      "  member_casual                     source_file  Unnamed: 0  \\\n",
      "0        member  202301-citibike-tripdata_1.csv         NaN   \n",
      "1        member  202301-citibike-tripdata_1.csv         NaN   \n",
      "2        member  202301-citibike-tripdata_1.csv         NaN   \n",
      "3        member  202301-citibike-tripdata_1.csv         NaN   \n",
      "4        member  202301-citibike-tripdata_1.csv         NaN   \n",
      "\n",
      "  rideable_type_duplicate_column_name_1  \n",
      "0                                   NaN  \n",
      "1                                   NaN  \n",
      "2                                   NaN  \n",
      "3                                   NaN  \n",
      "4                                   NaN  \n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s  %(levelname)s  %(message)s\", handlers=[logging.StreamHandler(sys.stdout)])\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"📅 Loading Citi Bike data from Jan 2023 to Mar 2025 …\")\n",
    "\n",
    "raw_rides_2023 = load_and_process_citibike_data_from_local(\n",
    "    year=2023,\n",
    "    months=list(range(1, 13)),\n",
    "    base_path=config.LOCAL_CITIBIKE_DATA_PATH\n",
    ")\n",
    "\n",
    "raw_rides_2024 = load_and_process_citibike_data_from_local(\n",
    "    year=2024,\n",
    "    months=list(range(1, 13)),\n",
    "    base_path=config.LOCAL_CITIBIKE_DATA_PATH\n",
    ")\n",
    "\n",
    "raw_rides_2025 = load_and_process_citibike_data_from_local(\n",
    "    year=2025,\n",
    "    months=[1, 2, 3],\n",
    "    base_path=config.LOCAL_CITIBIKE_DATA_PATH\n",
    ")\n",
    "\n",
    "raw_rides = pd.concat([raw_rides_2023, raw_rides_2024, raw_rides_2025])\n",
    "logger.info(f\"✅ Total rows loaded: {len(raw_rides):,}\")\n",
    "\n",
    "print(raw_rides[\"pickup_location_id\"].unique())\n",
    "\n",
    "print(raw_rides.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ced5443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:28:09,095 INFO: 📉 Filtered for top 3 stations: 799,733 rows\n"
     ]
    }
   ],
   "source": [
    "TOP_3_IDS = {\"6140.05\", \"6948.10\", \"5329.03\"}\n",
    "\n",
    "raw_rides_top3 = raw_rides[raw_rides[\"pickup_location_id\"].astype(str).isin(TOP_3_IDS)].copy()\n",
    "logger.info(f\"📉 Filtered for top 3 stations: {len(raw_rides_top3):,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6852dfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>source_file</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rideable_type_duplicate_column_name_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A46D077151843D7B</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-16 10:39:54.386</td>\n",
       "      <td>2023-01-16 10:45:18.005</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>202301-citibike-tripdata_1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233875BAED2E02D0</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-12 16:55:30.755</td>\n",
       "      <td>2023-01-12 17:04:03.688</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>202301-citibike-tripdata_1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8DD222EA1A1B0BC9</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-01-08 19:32:25.647</td>\n",
       "      <td>2023-01-08 19:42:00.382</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717618</td>\n",
       "      <td>-74.013071</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>202301-citibike-tripdata_1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58976A4F584F8D28</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-27 20:01:52.897</td>\n",
       "      <td>2023-01-27 20:08:58.118</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>202301-citibike-tripdata_1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FDD4C1E89A26727C</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-13 18:02:38.160</td>\n",
       "      <td>2023-01-13 18:11:22.139</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>202301-citibike-tripdata_1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type         pickup_datetime  \\\n",
       "0  A46D077151843D7B   classic_bike 2023-01-16 10:39:54.386   \n",
       "1  233875BAED2E02D0   classic_bike 2023-01-12 16:55:30.755   \n",
       "2  8DD222EA1A1B0BC9  electric_bike 2023-01-08 19:32:25.647   \n",
       "3  58976A4F584F8D28   classic_bike 2023-01-27 20:01:52.897   \n",
       "4  FDD4C1E89A26727C   classic_bike 2023-01-13 18:02:38.160   \n",
       "\n",
       "                  ended_at     start_station_name pickup_location_id  \\\n",
       "0  2023-01-16 10:45:18.005  West St & Chambers St            5329.03   \n",
       "1  2023-01-12 17:04:03.688  West St & Chambers St            5329.03   \n",
       "2  2023-01-08 19:42:00.382  West St & Chambers St            5329.03   \n",
       "3  2023-01-27 20:08:58.118  West St & Chambers St            5329.03   \n",
       "4  2023-01-13 18:11:22.139  West St & Chambers St            5329.03   \n",
       "\n",
       "  end_station_name end_station_id  start_lat  start_lng    end_lat    end_lng  \\\n",
       "0   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "1   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "2   West Thames St        5114.06  40.717618 -74.013071  40.708347 -74.017134   \n",
       "3   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "4   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "\n",
       "  member_casual                     source_file  Unnamed: 0  \\\n",
       "0        member  202301-citibike-tripdata_1.csv         NaN   \n",
       "1        member  202301-citibike-tripdata_1.csv         NaN   \n",
       "2        member  202301-citibike-tripdata_1.csv         NaN   \n",
       "3        member  202301-citibike-tripdata_1.csv         NaN   \n",
       "4        member  202301-citibike-tripdata_1.csv         NaN   \n",
       "\n",
       "  rideable_type_duplicate_column_name_1  \n",
       "0                                   NaN  \n",
       "1                                   NaN  \n",
       "2                                   NaN  \n",
       "3                                   NaN  \n",
       "4                                   NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_rides_top3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca6bfdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:28:19,876 INFO: 🧮 Aggregating to hourly time-series format …\n",
      "2025-05-03 22:28:20,114 INFO: ✅ Transformed data shape: (59367, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-28 11:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-28 12:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-28 13:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-28 14:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-28 15:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_hour pickup_location_id  rides\n",
       "0 2022-12-28 11:00:00            5329.03      1\n",
       "1 2022-12-28 12:00:00            5329.03      0\n",
       "2 2022-12-28 13:00:00            5329.03      0\n",
       "3 2022-12-28 14:00:00            5329.03      0\n",
       "4 2022-12-28 15:00:00            5329.03      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info(\"🧮 Aggregating to hourly time-series format …\")\n",
    "ts_data = transform_raw_data_into_ts_data(raw_rides_top3)\n",
    "logger.info(f\"✅ Transformed data shape: {ts_data.shape}\")\n",
    "ts_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee591a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-03 18:34:25,666 INFO: 🔐 Logging in to Hopsworks …\n",
      "2025-05-03 18:34:25,671 INFO: Initializing external client\n",
      "2025-05-03 18:34:25,671 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-03 18:34:26,600 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1214683\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"🔐 Logging in to Hopsworks …\")\n",
    "project = hopsworks.login(\n",
    "    project=config.HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value=config.HOPSWORKS_API_KEY,\n",
    ")\n",
    "fs = project.get_feature_store()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ecffb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-03 18:35:12,884 INFO: 📦 Writing to Hopsworks feature group …\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1214683/fs/1202314/fg/1452362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 59367/59367 | Elapsed Time: 00:04 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: time_series_hourly_feature_group_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1214683/jobs/named/time_series_hourly_feature_group_1_offline_fg_materialization/executions\n",
      "2025-05-03 18:35:28,870 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-05-03 18:35:31,961 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-05-03 18:37:54,008 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-05-03 18:37:54,075 INFO: Waiting for log aggregation to finish.\n",
      "2025-05-03 18:38:02,389 INFO: Execution finished successfully.\n",
      "2025-05-03 18:38:02,392 INFO: ✅ Done uploading data to Hopsworks!\n"
     ]
    }
   ],
   "source": [
    "from hsfs.feature import Feature\n",
    "\n",
    "fg_schema = [\n",
    "    Feature(\"pickup_hour\",        \"timestamp\"),\n",
    "    Feature(\"pickup_location_id\", \"string\"),\n",
    "    Feature(\"rides\",              \"int\"),\n",
    "]\n",
    "\n",
    "logger.info(\"📦 Writing to Hopsworks feature group …\")\n",
    "hourly_fg = fs.get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION,\n",
    "    description=\"Hourly Citi Bike rides per location (2023–2025)\",\n",
    "    primary_key=[\"pickup_hour\", \"pickup_location_id\"],\n",
    "    event_time=\"pickup_hour\",\n",
    "    online_enabled=False,\n",
    "    features=fg_schema,\n",
    ")\n",
    "\n",
    "ts_data[\"pickup_location_id\"] = ts_data[\"pickup_location_id\"].astype(str)\n",
    "ts_data[\"rides\"] = ts_data[\"rides\"].astype(\"int32\")\n",
    "\n",
    "hourly_fg.insert(ts_data, write_options={\"wait_for_job\": True})\n",
    "logger.info(\"✅ Done uploading data to Hopsworks!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be755da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-03 18:43:29,993 INFO: 🔎 Creating Feature View …\n",
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1214683/fs/1202314/fv/time_series_hourly_feature_view/version/1\n",
      "2025-05-03 18:43:31,954 INFO: ✅ Feature View created successfully.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"🔎 Creating Feature View …\")\n",
    "\n",
    "from hsfs.feature import Feature\n",
    "\n",
    "feature_group = fs.get_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION\n",
    ")\n",
    "\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name=config.FEATURE_VIEW_NAME,\n",
    "    version=config.FEATURE_VIEW_VERSION,\n",
    "    description=\"Feature view for Citi Bike hourly demand\",\n",
    "    labels=[],\n",
    "    query=feature_group.select_all()\n",
    ")\n",
    "\n",
    "logger.info(\"✅ Feature View created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a0c2030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:32:52,378 INFO: 📊 Generating sliding window features …\n",
      "✅ Transformed shape: (57351, 675)\n",
      "✅ Sample columns: ['rides_t-672', 'rides_t-671', 'rides_t-670', 'rides_t-669', 'rides_t-668', '...', 'target', 'pickup_hour', 'pickup_location_id']\n"
     ]
    }
   ],
   "source": [
    "from src.data_utils import transform_ts_data_info_features_and_target_loop\n",
    "\n",
    "logger.info(\"📊 Generating sliding window features …\")\n",
    "\n",
    "# Use correct window size\n",
    "window_size = 672\n",
    "\n",
    "# Get full transformed DataFrame with all metadata\n",
    "features_df, _ = transform_ts_data_info_features_and_target_loop(\n",
    "    ts_data, feature_col=\"rides\", window_size=window_size, step_size=1\n",
    ")\n",
    "\n",
    "# Check shape and available columns\n",
    "print(\"✅ Transformed shape:\", features_df.shape)\n",
    "print(\"✅ Sample columns:\", features_df.columns[:5].tolist() + [\"...\", features_df.columns[-3], features_df.columns[-2], features_df.columns[-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe1df65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rides_t-672</th>\n",
       "      <th>rides_t-671</th>\n",
       "      <th>rides_t-670</th>\n",
       "      <th>rides_t-669</th>\n",
       "      <th>rides_t-668</th>\n",
       "      <th>rides_t-667</th>\n",
       "      <th>rides_t-666</th>\n",
       "      <th>rides_t-665</th>\n",
       "      <th>rides_t-664</th>\n",
       "      <th>rides_t-663</th>\n",
       "      <th>...</th>\n",
       "      <th>rides_t-7</th>\n",
       "      <th>rides_t-6</th>\n",
       "      <th>rides_t-5</th>\n",
       "      <th>rides_t-4</th>\n",
       "      <th>rides_t-3</th>\n",
       "      <th>rides_t-2</th>\n",
       "      <th>rides_t-1</th>\n",
       "      <th>target</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-01-25 11:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-25 12:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-25 13:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-25 14:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-25 15:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 675 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
       "0            1            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
       "0            0            0            0            0            0  ...   \n",
       "1            0            0            0            0            0  ...   \n",
       "2            0            0            0            0            0  ...   \n",
       "3            0            0            0            0            0  ...   \n",
       "4            0            0            0            0            0  ...   \n",
       "\n",
       "   rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  rides_t-2  \\\n",
       "0          0          0          5         12         15         12   \n",
       "1          0          5         12         15         12          4   \n",
       "2          5         12         15         12          4          6   \n",
       "3         12         15         12          4          6          2   \n",
       "4         15         12          4          6          2          5   \n",
       "\n",
       "   rides_t-1  target         pickup_hour  pickup_location_id  \n",
       "0          4       6 2023-01-25 11:00:00             5329.03  \n",
       "1          6       2 2023-01-25 12:00:00             5329.03  \n",
       "2          2       5 2023-01-25 13:00:00             5329.03  \n",
       "3          5       2 2023-01-25 14:00:00             5329.03  \n",
       "4          2       0 2023-01-25 15:00:00             5329.03  \n",
       "\n",
       "[5 rows x 675 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f8afd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➜ Trained model expected 676 features\n",
      "First 5: ['rides_t-672', 'rides_t-671', 'rides_t-670', 'rides_t-669', 'rides_t-668']\n",
      "Last 5:  ['rides_t-1', 'target', 'average_rides_last_4_weeks', 'hour', 'day_of_week']\n",
      "➜ Your X has 674 columns.\n",
      "First 5: ['rides_t-672', 'rides_t-671', 'rides_t-670', 'rides_t-669', 'rides_t-668']\n",
      "Last 5:  ['rides_t-3', 'rides_t-2', 'rides_t-1', 'pickup_hour', 'pickup_location_id']\n",
      "✖ Features expected by model but missing in X: ['average_rides_last_4_weeks', 'day_of_week', 'hour', 'target']\n",
      "✖ Extra columns in X that the model didn’t expect: ['pickup_hour', 'pickup_location_id']\n"
     ]
    }
   ],
   "source": [
    "# 0️⃣ load the full Pipeline\n",
    "import os, sys, joblib\n",
    "\n",
    "model_path = os.path.abspath(\n",
    "    os.path.join(os.getcwd(), \"..\", \"models\", \"lgb_model.pkl\")\n",
    ")\n",
    "lgb_pipeline = joblib.load(model_path)\n",
    "\n",
    "# 1️⃣ pull out the underlying Booster and its feature‐name list\n",
    "#   (depends on whether you have a plain LGBMModel or a sklearn Pipeline)\n",
    "if hasattr(lgb_pipeline, \"booster_\"):\n",
    "    booster = lgb_pipeline.booster_\n",
    "elif hasattr(lgb_pipeline, \"_Booster\"):\n",
    "    booster = lgb_pipeline._Booster\n",
    "else:\n",
    "    # assume a Pipeline and last step is the LGB\n",
    "    booster = lgb_pipeline.steps[-1][1].booster_\n",
    "\n",
    "expected = booster.feature_name()\n",
    "print(\"➜ Trained model expected\", len(expected), \"features\")\n",
    "print(\"First 5:\", expected[:5])\n",
    "print(\"Last 5: \", expected[-5:])\n",
    "\n",
    "# 2️⃣ build your X exactly as you have it now\n",
    "lag_cols   = [c for c in features_df.columns if c.startswith(\"rides_t-\")]\n",
    "input_cols = lag_cols + [\"pickup_hour\", \"pickup_location_id\"]\n",
    "X = features_df[input_cols]\n",
    "\n",
    "print(\"➜ Your X has\", X.shape[1], \"columns.\")\n",
    "print(\"First 5:\", X.columns[:5].tolist())\n",
    "print(\"Last 5: \", X.columns[-5:].tolist())\n",
    "\n",
    "# 3️⃣ see which names don’t line up\n",
    "missing_in_X   = set(expected) - set(X.columns)\n",
    "extra_in_X     = set(X.columns) - set(expected)\n",
    "print(\"✖ Features expected by model but missing in X:\", sorted(missing_in_X))\n",
    "print(\"✖ Extra columns in X that the model didn’t expect:\", sorted(extra_in_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7eec5b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>predicted_rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-25 11:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>5.999306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-25 12:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>1.998759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-25 13:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>4.998313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-25 14:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>1.998759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-25 15:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>0.001673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_hour pickup_location_id  predicted_rides\n",
       "0 2023-01-25 11:00:00            5329.03         5.999306\n",
       "1 2023-01-25 12:00:00            5329.03         1.998759\n",
       "2 2023-01-25 13:00:00            5329.03         4.998313\n",
       "3 2023-01-25 14:00:00            5329.03         1.998759\n",
       "4 2023-01-25 15:00:00            5329.03         0.001673"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, joblib\n",
    "import pandas as pd\n",
    "\n",
    "# 1️⃣ Locate & load your full pipeline (with featurizer + LGB):\n",
    "model_path = os.path.abspath(\n",
    "    os.path.join(os.getcwd(), \"..\", \"models\", \"lgb_model.pkl\")\n",
    ")\n",
    "pipeline = joblib.load(model_path)\n",
    "\n",
    "# 2️⃣ Build the raw X exactly as the pipeline saw it at train time:\n",
    "lag_cols = [c for c in features_df.columns if c.startswith(\"rides_t-\")]\n",
    "\n",
    "X_raw = features_df[ \n",
    "    lag_cols\n",
    "    + [\"target\", \"pickup_hour\", \"pickup_location_id\"]\n",
    "].copy()\n",
    "\n",
    "# 3️⃣ Now run it:\n",
    "preds = pipeline.predict(X_raw)\n",
    "\n",
    "# 4️⃣ Stick them back:\n",
    "features_df = features_df.copy()\n",
    "features_df[\"predicted_rides\"] = preds\n",
    "\n",
    "features_df[[\"pickup_hour\", \"pickup_location_id\", \"predicted_rides\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8207b47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>predicted_rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-25 11:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-25 12:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-25 13:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-25 14:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-25 15:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_hour pickup_location_id  predicted_rides\n",
       "0 2023-01-25 11:00:00            5329.03                6\n",
       "1 2023-01-25 12:00:00            5329.03                2\n",
       "2 2023-01-25 13:00:00            5329.03                5\n",
       "3 2023-01-25 14:00:00            5329.03                2\n",
       "4 2023-01-25 15:00:00            5329.03                0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, joblib\n",
    "import pandas as pd\n",
    "\n",
    "# 0️⃣ If you haven’t already, make sure your notebook can see ../models\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# 1️⃣ Load the full sklearn Pipeline you trained\n",
    "model_path = os.path.join(os.getcwd(), \"..\", \"models\", \"lgb_model.pkl\")\n",
    "assert os.path.exists(model_path), f\"Model not found: {model_path}\"\n",
    "pipeline = joblib.load(model_path)\n",
    "\n",
    "# 2️⃣ Build the raw X exactly as your pipeline saw it at train time:\n",
    "#    - ALL lag features (\"rides_t-...\") \n",
    "#    - the placeholder \"target\" column (pipeline will drop it internally)\n",
    "#    - pickup_hour (for hour/day features)\n",
    "#    - pickup_location_id (so the pipeline’s drop-step can find it)\n",
    "lag_cols = [col for col in features_df.columns if col.startswith(\"rides_t-\")]\n",
    "X_raw   = features_df[lag_cols + [\"target\", \"pickup_hour\", \"pickup_location_id\"]].copy()\n",
    "\n",
    "# 3️⃣ Run the pipeline’s predict (it will extend with avg/day/hour, drop extras, then LGBM)\n",
    "preds = pipeline.predict(X_raw)\n",
    "\n",
    "# 4️⃣ Round to int32 (since your FG schema is `int`)\n",
    "features_df = features_df.copy()  # avoid any warning\n",
    "features_df[\"predicted_rides\"] = preds.round(0).astype(\"int32\")\n",
    "\n",
    "# 5️⃣ Quick sanity check\n",
    "features_df[[\"pickup_hour\", \"pickup_location_id\", \"predicted_rides\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d443097f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57351, 676)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dc4d78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          pickup_hour pickup_location_id  predicted_rides\n",
      "0 2023-01-25 11:00:00            5329.03                6\n",
      "1 2023-01-25 12:00:00            5329.03                2\n",
      "2 2023-01-25 13:00:00            5329.03                5\n",
      "3 2023-01-25 14:00:00            5329.03                2\n",
      "4 2023-01-25 15:00:00            5329.03                0\n"
     ]
    }
   ],
   "source": [
    "# quick sanity‑check\n",
    "print(features_df[[\"pickup_hour\", \"pickup_location_id\", \"predicted_rides\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38862702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction FG version: 2\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import src.config as c\n",
    "print(\"Prediction FG version:\", c.FEATURE_GROUP_MODEL_PREDICTION_VERSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2aec7908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-03 23:03:33,604 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-03 23:03:33,608 INFO: Initializing external client\n",
      "2025-05-03 23:03:33,609 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-03 23:03:34,570 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1214683\n",
      "✅ Using Feature Group “taxi_hourly_model_prediction” v2 (id None)\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1214683/fs/1202314/fg/1438379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 57351/57351 | Elapsed Time: 00:04 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: taxi_hourly_model_prediction_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1214683/jobs/named/taxi_hourly_model_prediction_2_offline_fg_materialization/executions\n",
      "2025-05-03 23:03:52,947 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-05-03 23:03:56,042 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-05-03 23:06:34,135 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-05-03 23:06:34,214 INFO: Waiting for log aggregation to finish.\n",
      "2025-05-03 23:06:42,586 INFO: Execution finished successfully.\n",
      "🚀  Predictions uploaded to Hopsworks!\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "from hsfs.feature import Feature\n",
    "import src.config as c\n",
    "\n",
    "# 1️⃣ Log in\n",
    "project = hopsworks.login(\n",
    "    project       = c.HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value = c.HOPSWORKS_API_KEY,\n",
    ")\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# 2️⃣ Get-or-create the prediction Feature Group v2\n",
    "pred_fg = fs.get_or_create_feature_group(\n",
    "    name          = c.FEATURE_GROUP_MODEL_PREDICTION,\n",
    "    version       = c.FEATURE_GROUP_MODEL_PREDICTION_VERSION,\n",
    "    description   = \"Next-hour demand predictions from LGBM model (v2)\",\n",
    "    primary_key   = [\"pickup_location_id\", \"pickup_hour\"],\n",
    "    event_time    = \"pickup_hour\",\n",
    "    online_enabled=False,\n",
    "    features      = [\n",
    "        Feature(\"pickup_location_id\", \"string\"),\n",
    "        Feature(\"pickup_hour\",        \"timestamp\"),\n",
    "        Feature(\"predicted_rides\",    \"int\"),\n",
    "    ],\n",
    ")\n",
    "print(f\"✅ Using Feature Group “{pred_fg.name}” v{pred_fg.version} (id {pred_fg.id})\")\n",
    "\n",
    "# 3️⃣ Prepare your output DataFrame exactly to schema\n",
    "out_df = features_df[[\"pickup_hour\", \"pickup_location_id\", \"predicted_rides\"]].copy()\n",
    "out_df[\"pickup_location_id\"] = out_df[\"pickup_location_id\"].astype(str)\n",
    "out_df[\"predicted_rides\"]    = out_df[\"predicted_rides\"].round(0).astype(\"int32\")\n",
    "\n",
    "# 4️⃣ Insert & wait for completion\n",
    "pred_fg.insert(out_df, write_options={\"wait_for_job\": True})\n",
    "print(\"🚀  Predictions uploaded to Hopsworks!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bcb0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp25_citibike",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
